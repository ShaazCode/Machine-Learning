{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmPr/KNkjUMpeMGq5HZ9Dj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaazCode/Machine-Learning/blob/main/Supervised_learning_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo3FrNLkS530"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"ShaazCode\"\n"
      ],
      "metadata": {
        "id": "o6USyRmRTT1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"shaaz.code@gmail.com\"\n"
      ],
      "metadata": {
        "id": "Ew0jmsCYTVrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShaazCode/Machine-Learning.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtWGTrx2Tejs",
        "outputId": "e6ce149d-a22c-4ec6-f327-c3020e3a4301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine-Learning'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 42 (delta 14), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (42/42), 178.20 KiB | 3.30 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Check Check\")"
      ],
      "metadata": {
        "id": "672IPTNwThlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification**"
      ],
      "metadata": {
        "id": "W9UvpiMrWoyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification is a type of supervised learning , just like a regression , the difference between both is target variable\n",
        "\n",
        "**Regression:** It is used to predict the continously value ( like price, temperature, salary)\n",
        "\n",
        "Classification: It is used to predict the category or class (dog or cat, span or not spam, etc)\n",
        "\n",
        "# **Working of classification**\n",
        "\n",
        "Step 1: Training phase (learning)- In this phase the algorithm studies the data\n",
        "It looks at:\n",
        "\n",
        "Features - actual information in each column\n",
        "\n",
        "Labels - the actual class or category for each row\n",
        "\n",
        "Then , it learn the relationship (a kind of a rule or boundary).\n",
        "Imagien a model saying : when i see this kind of data , it usually belongs to class A, and when i see this kind of data then it belongs to class b.\n",
        "\n",
        "(mtlb classification me phle column and label/target value dekhi jati hai mtlb ki vo ek relationship banata hai data ko dekh ke like agr features aise hai to ye output aa skta hai)\n",
        "\n",
        "\n",
        "Step 2: Decision boundary formation\n",
        "\n",
        "After learning , the model form the internal rule (a line, plane, curve) that seperates differents classes.\n",
        "\n",
        "you can imagien like drawing an invisible line that divides one category in data space.\n",
        "\n",
        "Step 3: Prediction phases:\n",
        "\n",
        "Now when new unseen data come into the model\n",
        "1. It look the input features\n",
        "2. Check which side of boundary the input lies on\n",
        "3. Assign a class label according to it\n",
        "\n",
        "So basically we can say what i learned before this new things looks more like class A than class B\n",
        "\n",
        "Step 4: Evaluation:\n",
        "\n",
        "Finally the model predicted output just checked with the actual answer to see how well it performed using measure like\n",
        "1. Accuracy\n",
        "2. Precision , Recall, F1 Score\n",
        "\n",
        "Input: Features (data you have)\n",
        "\n",
        "Output: Class label (category you want)\n",
        "\n",
        "Goal: Find a mapping (relationship) from features → class\n",
        "\n",
        "Working: Model learns boundaries or patterns that help it tell one class from another"
      ],
      "metadata": {
        "id": "vJtrnt8gWsBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Type**\n"
      ],
      "metadata": {
        "id": "-gCj2JnXXFcc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification are mainly divided into 3 major types based on the number of classes\n",
        "\n",
        "1. Binary Classification\n",
        "\n",
        "2. Multi-class classification\n",
        "\n",
        "3. Multilabel classificaition"
      ],
      "metadata": {
        "id": "39uUJPydd6DN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Binary Classification**\n",
        "\n",
        "When there are only two possible output classes like yes/no , true/false, positive/negative that time we make use of binary classification. - (idea is to seperaqte data into two groups)\n",
        "\n",
        "Thik of it decision with two choices.\n",
        "you look at an email and ask - \"Is this spam or not spam\"\n",
        "\n",
        "\n",
        "# ***Follow multiclass learning working so this both works same please dont refer this ***\n",
        "How binary classification works:\n",
        "\n",
        "Step 1: Trainign Data- We first collect the data that has already labelled\n",
        "\n",
        "Example of dataset\n",
        "\n",
        "| Email Text             | Label        |\n",
        "| ---------------------- | ------------ |\n",
        "| \"Win a free iPhone!\"   | Spam (1)     |\n",
        "| \"Meeting at 3 PM\"      | Not Spam (0) |\n",
        "| \"Limited time offer!\"  | Spam (1)     |\n",
        "| \"Here is your invoice\" | Not Spam (0) |\n",
        "\n",
        "\n",
        "here the input(x) = email text\n",
        "output (y) Label - spam or not\n",
        "\n",
        "so see here there's only one input here the number of input doesnot matter it can be one or more.\n",
        "\n",
        "step 2: Learning the pattern:\n",
        "The model look at all the example and find the pattern,\n",
        "spam email often contain words like urgent, free, offer, win , etc\n",
        "not spam email often contain word like meeting, project, report , invoice.\n",
        "\n",
        "step 3: Decision boundary\n",
        "the model draw imaginary line (boundary) seperates :    \n",
        "spam email on one side\n",
        "not spam on other side\n",
        "\n",
        "so now when a email comes then it checks which side of line it falls.\n",
        "\n",
        "step 4: Prediction\n",
        "\n",
        "Now when a new unseen email appear\n",
        "If it falls on the spam side  -> Predict 1 (spam)\n",
        "If it's falls on the non spam side -> Predict (not spam)\n",
        "\n",
        "The model will also output probably like\n",
        "0.8 -> 80% chance of spam -> Predict spam\n",
        "0.2 -> 20% chance of spam -> Predict non spam\n",
        "\n",
        "\n",
        "In simple words we can say:\n",
        "Learn from labeled examples\n",
        "\n",
        "Find the best boundary/rule that separates the two classes\n",
        "\n",
        "Predict the correct class for unseen data\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Collect the data : Input (features) output (classes)\n",
        "\n",
        "2. Process the data - clean , scale the data\n",
        "\n",
        "3. Split the data - Train + test\n",
        "\n",
        "4. choose a model - logistic regression , SVM , decision tree\n",
        "\n",
        "5. Train the model - model runs to seperate the two classes\n",
        "\n",
        "6. Predict - Model output probability\n",
        "\n",
        "7. Evaluate performance"
      ],
      "metadata": {
        "id": "MTUpnEYDeh3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiclass classification**\n",
        "\n",
        "If we are having more than 2 output classes, then we make use of multiclass classification.\n",
        "\n",
        "Example: Given an image, classify it as one of: cat, dog, rabbit. That’s a multiclass problem.\n",
        "\n",
        "\n",
        "steps:\n",
        "1. Collect the data: Input (feature) + output with 3 or more classes.\n",
        "\n",
        "2. Preprocess the data - Clean the data and encode the data\n",
        "\n",
        "3. split data - solitting into train and test data\n",
        "\n",
        "4. choose the model - choose any model that is supporting multi-class (softmax regression, decision tree, SVM, random forest, neural networks)\n",
        "\n",
        "5. Train the model - model leanrs to differentiate between multiple classes.\n",
        "\n",
        "6. Predict - model outputs the class with highest probability\n",
        "\n",
        "7. Evaluate the accuracy:\n",
        "\n",
        "# **How it learns?**\n",
        "\n",
        "It learns using seeing input data + correct class\n",
        "\n",
        "Step 1: look at many example - it keeps learning what makes each class different\n",
        "\n",
        "step 2: learn unique feature for each class\n",
        "\n",
        "If color is yellow look like more as Banana\n",
        "If color is red + round looks like more as apple\n",
        "If color is round + orange looks like more as orange\n",
        "It learn this rules automatically\n",
        "\n",
        "Step 3: make Decision boundaries- Imagine drawing invisible lines that separate classes\n",
        "\n",
        "Step 4: Improve and reduce the mistake - Then it adjusts rules until mistakes become minimum.\n",
        "\n",
        "Step 5: Final output- Model calculate the probability for each class and then it chooses the class with highest probability\n",
        "\n",
        "| Class  | Probability |\n",
        "| ------ | ----------- |\n",
        "| Apple  | 0.10        |\n",
        "| Banana | 0.20        |\n",
        "| Orange | ⭐0.70       |\n",
        "\n",
        "Final Prediction → Orange\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbihFM0hZlfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-labelled classification**"
      ],
      "metadata": {
        "id": "zKQv3I3_gXKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi labelled classifications means one single input can belongs to multiple classes at a same time.\n",
        "\n",
        "Example:\n",
        "\n",
        "A movie can be dramatic + horror at a same time\n",
        "so one item many label\n",
        "\n",
        "How It Learns (Concept)\n",
        "\n",
        "The model learns patterns for each label independently\n",
        "\n",
        "It predicts yes/no for every label separately\n",
        "\n",
        "So it works like multiple binary classifiers combined\n",
        "\n"
      ],
      "metadata": {
        "id": "OhXKUozMgcdz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IwH4dzLwVABH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}